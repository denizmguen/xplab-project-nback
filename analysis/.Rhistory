p.hypotheses = rbind(p.hypotheses, data.frame(H1a = p.H1a.n4, H1b = p.H1b.n4))
p.hypotheses$n <- as.factor(c(3,4))
print(p.hypotheses)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(plotly)
#Creating dataframe for individual participants.
subject = subset(accu_complete, submission_id == subject.id)
```{r include=FALSE}
```{r include=FALSE}
subject.id = 1
group = "control"
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(plotly)
```{r setting seed, include=FALSE}
```{r setting seed, include=FALSE}
```{r setting seed, include=FALSE}
```{r setting seed, include=FALSE}
```{r setting seed, include=FALSE}
set.seed(100) # this ensures that any psuedo-random computations are always the same
data.raw = data.frame(read.csv("fake_data.csv"))
data_pertinent = subset(data.raw, trial_name != "practice" & trial_number > n)
data = subset(data_pertinent, select= c(stim_type,correctness,RT,trial_name,n,trial_number,submission_id))
# Add gross stimtype
gross = data$stim_type
gross = ifelse(data$stim_type == "target", "target", "non-target")
data$gross_stimtype = gross
#Grouping by ID stim type, trial name and n --- 'nn' is the total number of trials for the specific variable combination of each row
grouped1 = data %>% group_by(submission_id,stim_type,gross_stimtype,trial_name,n)
cg1 = count(grouped1)
#Grouping by correctness for counts of "correct" or "incorrect" --- 'nn' is number of correct trials for the specific variable combination of each row
grouped2 = grouped1 %>% group_by(correctness, add=TRUE)
cg2 = count(grouped2)
# Accuracy table must be a table with the following rows: ID, trial_name, n, stimulus_type, gross_stimulus_type and accuracy
accuracy_table <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(accuracy_table) <- c("ID","trial_name", "stimulus_type","gross_stimulus_type","n", "accuracy")
# Defining the right variable types for cols.
accuracy_table$submission_id <- as.factor(accuracy_table$submission_id)
accuracy_table$accuracy <- as.numeric(accuracy_table$accuracy)
accuracy_table$n <- as.factor(accuracy_table$n)
accu_id = subset(accuracy_table, select=c(ID,trial_name,n,accuracy)) # seperate n's
for(id in IDs){
for(n in N){
howmanyback = n
trial_name = filter(data,submission_id==id)$trial_name[1]
n_correct = filter(cg2, (submission_id == id) && (n == howmanyback & correctness == "correct"))$nn
n_correct = sum(n_correct)
n_total = 100
accuracy = n_correct/n_total
entry = data.frame(submission_id=id, trial_name=trial_name, n=n, accuracy=accuracy)
accu_id <- rbind(accu_id, entry)
}
}
'
ids = accu_id$submission_id
comments = lapply(ids,
FUN=function(x){subset(data.raw, submission_id==x)$comments[1] %>% as.character() %>%  return()})
## Print accuracies and comments
for(i in c(1:nrow(accu_id))){
output = sprintf("id: %d \n n: %s, \n accuracy: %f \n comment: %s \n trial: %s \n",
accu_id$submission_id[i], accu_id$n[i], accu_id$accuracy[i], comments[i], accu_id$trial_name[i])
cat(output)
}
accu_id$submission_id <- accu_id$submission_id %>% as.factor()
'
subject.plot.data = subset(accu_id, trial_name==group)
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_hline(yintercept=mean(subset(subject.plot.data, n==3)$accuracy), color="#F8766D", size=1.2)+
geom_hline(yintercept=mean(subset(subject.plot.data, n==4)$accuracy), color="#00BFC4", size=1.2)+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy))
for(id in IDs){
for(n in N){
for(st in stim_types){
howmanyback = n
trial_name = filter(data,submission_id==id)$trial_name[1]
gr_st = filter(data, stim_type == st)$gross_stimtype[1]
n_correct = sum( filter(cg2, (submission_id == id && stim_type == st) && (n == howmanyback && correctness == "correct"))$nn )
n_total = sum( filter(cg2, (submission_id == id && n == howmanyback) && stim_type == st)$nn )
accuracy = n_correct/n_total
entry = data.frame(submission_id = id, trial_name = trial_name, stimulus_type = st, gross_stimulus_type = gr_st, n = howmanyback, accuracy = accuracy, count = n_total)
accu_complete <- rbind(accu_complete, entry)
}
}
}
#Creating dataframe for individual participants.
subject = subset(accu_complete, submission_id == subject.id)
pl.full = ggplot(accu_complete,mapping=aes(x=stimulus_type, y=accuracy, color=n))+ggtitle(sprintf("Accuracies by Stimulus Type and performance of subject %s", subject.id))+
geom_boxplot() +
geom_point(data=subject, size=3)
invisible(ggplotly(pl.full))
invisible(ggplotly(pl.full))
ggplotly(pl.full)
#Creating dataframe for individual participants.
subject = subset(accu_complete, submission_id == subject.id)
pl.full = ggplot(accu_complete,mapping=aes(x=stimulus_type, y=accuracy, color=n))+ggtitle(sprintf("Accuracies by Stimulus Type and performance of subject %s", subject.id))+
geom_boxplot() +
geom_point(data=subject, size=3)
ggplotly(pl.full)
(ggpl <- ggplotly(pl))
#Creating dataframe for individual participants.
subject = subset(accu_complete, submission_id == subject.id)
pl.full = ggplot(accu_complete,mapping=aes(x=stimulus_type, y=accuracy, color=n))+ggtitle(sprintf("Accuracies by Stimulus Type and performance of subject %s", subject.id))+
geom_boxplot() +
geom_point(data=subject, size=3)
ggplotly(pl.full)
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy))
for(id in IDs){
for(n in N){
for(st in stim_types){
howmanyback = n
trial_name = filter(data,submission_id==id)$trial_name[1]
gr_st = filter(data, stim_type == st)$gross_stimtype[1]
n_correct = sum( filter(cg2, (submission_id == id && stim_type == st) && (n == howmanyback && correctness == "correct"))$nn )
n_total = sum( filter(cg2, (submission_id == id && n == howmanyback) && stim_type == st)$nn )
accuracy = n_correct/n_total
entry = data.frame(submission_id = id, trial_name = trial_name, stimulus_type = st, gross_stimulus_type = gr_st, n = howmanyback, accuracy = accuracy, count = n_total)
accu_complete <- rbind(accu_complete, entry)
}
}
}
invisible(
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy))
for(id in IDs){
invisible(
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy)),
for(id in IDs){
for(n in N){
for(st in stim_types){
howmanyback = n
trial_name = filter(data,submission_id==id)$trial_name[1]
gr_st = filter(data, stim_type == st)$gross_stimtype[1]
n_correct = sum( filter(cg2, (submission_id == id && stim_type == st) && (n == howmanyback && correctness == "correct"))$nn )
n_total = sum( filter(cg2, (submission_id == id && n == howmanyback) && stim_type == st)$nn )
accuracy = n_correct/n_total
entry = data.frame(submission_id = id, trial_name = trial_name, stimulus_type = st, gross_stimulus_type = gr_st, n = howmanyback, accuracy = accuracy, count = n_total)
accu_complete <- rbind(accu_complete, entry)
}
}
}
)
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy)),
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy))
for(id in IDs){
for(n in N){
for(st in stim_types){
howmanyback = n
trial_name = filter(data,submission_id==id)$trial_name[1]
gr_st = filter(data, stim_type == st)$gross_stimtype[1]
n_correct = sum( filter(cg2, (submission_id == id && stim_type == st) && (n == howmanyback && correctness == "correct"))$nn )
n_total = sum( filter(cg2, (submission_id == id && n == howmanyback) && stim_type == st)$nn )
accuracy = n_correct/n_total
entry = data.frame(submission_id = id, trial_name = trial_name, stimulus_type = st, gross_stimulus_type = gr_st, n = howmanyback, accuracy = accuracy, count = n_total)
accu_complete <- rbind(accu_complete, entry)
}
}
}
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy))
for(id in IDs){
for(n in N){
for(st in stim_types){
howmanyback = n
trial_name = filter(data,submission_id==id)$trial_name[1]
gr_st = filter(data, stim_type == st)$gross_stimtype[1]
n_correct = sum( filter(cg2, (submission_id == id && stim_type == st) && (n == howmanyback && correctness == "correct"))$nn )
n_total = sum( filter(cg2, (submission_id == id && n == howmanyback) && stim_type == st)$nn )
accuracy = n_correct/n_total
entry = data.frame(submission_id = id, trial_name = trial_name, stimulus_type = st, gross_stimulus_type = gr_st, n = howmanyback, accuracy = accuracy, count = n_total)
accu_complete <- rbind(accu_complete, entry)
}
}
}
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_abline()
subject.plot.data = subset(accu_id, trial_name==group)
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_abline()
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_abline()+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
subject.plot.data = subset(accu_id, trial_name==group)
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_abline()+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
(ggpl <- ggplotly(pl))
subject.plot.data = subset(accu_id, trial_name==group)
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_abline(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
)
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_abline(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
(ggpl <- ggplotly(pl))
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_hline(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
subject.plot.data = subset(accu_id, trial_name==group)
pl = ggplot(data=subject.plot.data, mapping=aes(x=submission_id, y=accuracy, color=n))+xlab("Subject")+ggtitle(sprintf("Performance of Subject %s in group '%s' ", subject.id, group))+
geom_point() +
geom_hline(yintercept=mean(subset(subject.plot.data, n==3)$accuracy), color="#F8766D", size=1.2)+
geom_hline(yintercept=mean(subset(subject.plot.data, n==4)$accuracy), color="#00BFC4", size=1.2)+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 3, color="black")+
geom_point(data=subset(accu_id, submission_id==subject.id), shape=18, size = 2) +
theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
(ggpl <- ggplotly(pl))
library(tidyverse)
library(rstan)
library(brms)
library(lme4)
options(mc.cores = max(parallel::detectCores()-1, 1)) # at least one core if the machine only has one
rstan_options(auto_write = TRUE)
ks.test(post.samples$b_stimulus_typelureMnP1, post.samples$b_stimulus_typelureMnM1)
ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")
, post.samples$b_stimulus_typelureMnM1 +
ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")
, post.samples$b_stimulus_typelureMnM1 +
ksn4 = ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")
ksn4[1]
ksn4[2]
ksn4[3]
ksn4[2]
print(ksn4[2])
# Testing wether lures at n+1 are significantly more accurate than lures at n-1
#[2] Is the p.value of the summary that is returned by ks()
p.H1c = ks(post.samples$b_stimulus_typelureMnP1, post.samples$b_stimulus_typelureMnM1)[2]
#Considering the interaction with and the intercept for n=4
p.H1c.n4 = ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")[2]
# Testing wether lures at n+1 are significantly more accurate than lures at n-1
#[2] Is the p.value of the summary that is returned by ks()
p.H1c = ks.test(post.samples$b_stimulus_typelureMnP1, post.samples$b_stimulus_typelureMnM1)[2]
#Considering the interaction with and the intercept for n=4
p.H1c.n4 = ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")[2]
p.hypotheses <- add_column(p.hypotheses, c(p.H1c, p.H1c.n4), .before="n")
colnames(p.hypotheses)[3] <- "H1c"
print(p.hypotheses)
post.samples = posterior_samples(accu_complete.mdl.brm)
#For n3
p.H1a = mean(post.samples$b_stimulus_typelureMnM1 < post.samples$b_stimulus_typenonMtarget)
p.H1b = mean(post.samples$b_stimulus_typelureMnP1 < post.samples$b_stimulus_typenonMtarget)
p.hypotheses = data.frame(H1a = p.H1a, H1b = p.H1b)
#For the interaction with n4
p.H1a.n4 = mean(post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4" +
post.samples$"b_n4" < post.samples$b_stimulus_typenonMtarget)
p.H1b.n4 = mean(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4" +
post.samples$"b_n4" < post.samples$b_stimulus_typenonMtarget)
p.hypotheses = rbind(p.hypotheses, data.frame(H1a = p.H1a.n4, H1b = p.H1b.n4))
p.hypotheses$n <- as.factor(c(3,4))
print(p.hypotheses)
print(p.hypotheses, digits=5)
print(p.hypotheses, digits=5)
# Testing wether lures at n+1 are significantly more accurate than lures at n-1
#[2] Is the p.value of the summary that is returned by ks()
p.H1c = ks.test(post.samples$b_stimulus_typelureMnP1, post.samples$b_stimulus_typelureMnM1)[2]
#Considering the interaction with and the intercept for n=4
p.H1c.n4 = ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")[2]
p.hypotheses <- add_column(p.hypotheses, c(p.H1c, p.H1c.n4), .before="n")
colnames(p.hypotheses)[3] <- "H1c"
print(p.hypotheses, digits=5)
print(p.hypotheses, digits=10)
#Considering the interaction with and the intercept for n=4
p.H1c.n4 = sum(ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")[2], digits= 10)
p.hypotheses <- add_column(p.hypotheses, c(p.H1c, p.H1c.n4), .before="n")
colnames(p.hypotheses)[3] <- "H1c"
print(p.hypotheses, digits=10)
print(tibble(p.hypotheses))
print(a.tibble(p.hypotheses))
print(as.tibble(p.hypotheses))
p.hypotheses$H1c[2]
p.hypotheses$H1c[2]
p.hypotheses$H1b[2]
p.hypotheses$H1a[2]
p.hypotheses$H1c[2]
p.hypotheses$H1c[2][2]
post.samples = posterior_samples(accu_complete.mdl.brm)
#For n3
p.H1a = mean(post.samples$b_stimulus_typelureMnM1 < post.samples$b_stimulus_typenonMtarget)
p.H1b = mean(post.samples$b_stimulus_typelureMnP1 < post.samples$b_stimulus_typenonMtarget)
p.hypotheses = data.frame(H1a = p.H1a, H1b = p.H1b)
#For the interaction with n4
p.H1a.n4 = mean(post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4" +
post.samples$"b_n4" < post.samples$b_stimulus_typenonMtarget)
p.H1b.n4 = mean(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4" +
post.samples$"b_n4" < post.samples$b_stimulus_typenonMtarget)
p.hypotheses = rbind(p.hypotheses, data.frame(H1a = p.H1a.n4, H1b = p.H1b.n4))
p.hypotheses$n <- as.factor(c(3,4))
print(p.hypotheses, digits=5)
post.samples = posterior_samples(accu_complete.mdl.brm)
#For n3
p.H1a = mean(post.samples$b_stimulus_typelureMnM1 < post.samples$Intercept)
p.H1b = mean(post.samples$b_stimulus_typelureMnP1 < post.samples$Intercept)
p.hypotheses = data.frame(H1a = p.H1a, H1b = p.H1b)
#For the interaction with n4
p.H1a.n4 = mean(post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4" +
post.samples$"b_n4" < post.samples$Intercept)
p.H1b.n4 = mean(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4" +
post.samples$"b_n4" < post.samples$Intercept)
p.hypotheses = rbind(p.hypotheses, data.frame(H1a = p.H1a.n4, H1b = p.H1b.n4))
p.hypotheses$n <- as.factor(c(3,4))
print(p.hypotheses, digits=5)
post.samples$Intercept
post.samples
post.samples = posterior_samples(accu_complete.mdl.brm)
#For n3
p.H1a = mean(post.samples$b_stimulus_typelureMnM1 < post.samples$b_Intercept)
p.H1b = mean(post.samples$b_stimulus_typelureMnP1 < post.samples$b_Intercept)
p.hypotheses = data.frame(H1a = p.H1a, H1b = p.H1b)
#For the interaction with n4
p.H1a.n4 = mean(post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4" +
post.samples$"b_n4" < post.samples$b_Intercept)
p.H1b.n4 = mean(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4" +
post.samples$"b_n4" < post.samples$b_Intercept)
p.hypotheses = rbind(p.hypotheses, data.frame(H1a = p.H1a.n4, H1b = p.H1b.n4))
p.hypotheses$n <- as.factor(c(3,4))
print(p.hypotheses, digits=5)
post.samples = posterior_samples(accu_complete.mdl.brm)
#For n3
p.H1a = mean(post.samples$b_stimulus_typelureMnM1 < post.samples$b_Intercept)
p.H1b = mean(post.samples$b_stimulus_typelureMnP1 < post.samples$b_Intercept)
p.hypotheses = data.frame(H1a = p.H1a, H1b = p.H1b)
#For the interaction with n4
p.H1a.n4 = mean(post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4" +
post.samples$"b_n4" < post.samples$b_Intercept)
p.H1b.n4 = mean(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4" +
post.samples$"b_n4" < post.samples$b_Intercept)
p.hypotheses = rbind(p.hypotheses, data.frame(H1a = p.H1a.n4, H1b = p.H1b.n4))
p.hypotheses$n <- as.factor(c(3,4))
print(p.hypotheses, digits=5)
# Testing wether lures at n+1 are significantly more accurate than lures at n-1
#[2] Is the p.value of the summary that is returned by ks()
p.H1c = ks.test(post.samples$b_stimulus_typelureMnP1, post.samples$b_stimulus_typelureMnM1)[2]
#Considering the interaction with and the intercept for n=4
p.H1c.n4 = ks.test(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4"
, post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4")[2]
p.hypotheses <- add_column(p.hypotheses, c(p.H1c, p.H1c.n4), .before="n")
colnames(p.hypotheses)[3] <- "H1c"
print(p.hypotheses)
render()
post.samples = posterior_samples(accu_complete.mdl.brm)
#For n3
p.H1a = mean(post.samples$b_stimulus_typelureMnM1 < post.samples$b_Intercept)
p.H1b = mean(post.samples$b_stimulus_typelureMnP1 < post.samples$b_Intercept)
p.hypotheses = data.frame(H1a = p.H1a, H1b = p.H1b)
#For the interaction with n4
p.H1a.n4 = mean(post.samples$b_stimulus_typelureMnM1 +
post.samples$"b_stimulus_typelureMnM1:n4" +
post.samples$"b_n4" < post.samples$b_Intercept)
p.H1b.n4 = mean(post.samples$b_stimulus_typelureMnP1 +
post.samples$"b_stimulus_typelureMnP1:n4" +
post.samples$"b_n4" < post.samples$b_Intercept)
p.hypotheses = rbind(p.hypotheses, data.frame(H1a = p.H1a.n4, H1b = p.H1b.n4))
p.hypotheses$n <- as.factor(c(3,4))
print(p.hypotheses)
library(tidyverse)
library(rstan)
library(brms)
library(lme4)
options(mc.cores = max(parallel::detectCores()-1, 1)) # at least one core if the machine only has one
rstan_options(auto_write = TRUE)
set.seed(100) # this ensures that any psuedo-random computations are always the same
data.raw = data.frame(read.csv("fake_data.csv"))
head(data.raw)
data_pertinent = subset(data.raw, trial_name != "practice" & trial_number > n)
```{r Import Data,message=TRUE, warning=TRUE, tidy=FALSE}
data_pertinent = subset(data.raw, trial_name != "practice" & trial_number > n)
data = subset(data_pertinent, select= c(stim_type,correctness,RT,trial_name,n,trial_number,submission_id))
grouped = count(group_by(data, submission_id))
ids_faulty = filter(grouped, n < 200)$submission_id
data = subset(data, !(submission_id %in% ids_faulty))
normalize = function(data) {
mu = mean(data)
sig = sd(data)
normalized = abs(data - mu)/sig
return(normalized)
}
rosner_outlier_removal = function(data, var.col, crit.value){
data$normalized = normalize(var.col)
maximum = c( max(data$normalized), min(data$normalized) ) %>% abs() %>% max()
if(maximum >= crit.value){
data <- subset(data, abs(data$normalized) != maximum)
return(rosner_test(data, data$normalized, crit.value))
} else {
return(data)
}
}
get_outliers = function(data, var.col,grouping.variables, crit.value){
#woo : "without outliers"
data.woo = rosner_outlier_removal(data=data, var.col=var.col, crit.value=crit.value)
data.woo = select(data.woo, c(1:(length(names(data.woo)))))
all = select(data, grouping.variables)
non_outliers = select(data.woo, grouping.variables)
outliers = anti_join(all,non_outliers)
return(outliers)
}
mean_rts = aggregate(data$RT, FUN=mean, by=list(data$submission_id, data$n))
names(mean_rts) = c("submission_id", "n", "x")
outliers = get_outliers(data=mean_rts, var.col=mean_rts$x,
grouping.variables=c("submission_id", "n"), crit.value=3)
outliers
if(nrow(outliers)>0){
for(row in c(1:nrow(outliers))){
sprintf("ID: %d, n: %d",outliers$submission_id[row], outliers$n[row] )
data <- subset(data, submission_id != outliers$submission_id[row] , n != outliers$n[row])
}
}
gross = data$stim_type
gross = ifelse(data$stim_type == "target", "target", "non-target")
data$gross_stimtype = gross
#Grouping by ID stim type, trial name and n --- 'nn' is the total number of trials for the specific variable combination of each row
grouped1 = data %>% group_by(submission_id,stim_type,gross_stimtype,trial_name,n)
cg1 = count(grouped1)
#Grouping by correctness for counts of "correct" or "incorrect" --- 'nn' is number of correct trials for the specific variable combination of each row
grouped2 = grouped1 %>% group_by(correctness, add=TRUE)
cg2 = count(grouped2)
# Getting list with unique values to iterate through in the following cells
IDs = unique(grouped1$submission_id)
stim_types = unique(grouped1$stim_type)
gross_stimtypes = unique(grouped1$gross_stimtype)
trial_names = c("main", "control")
N = c("3", "4")
# Accuracy table must be a table with the following rows: ID, trial_name, n, stimulus_type, gross_stimulus_type and accuracy
accuracy_table <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(accuracy_table) <- c("ID","trial_name", "stimulus_type","gross_stimulus_type","n", "accuracy")
# Defining the right variable types for cols.
accuracy_table$submission_id <- as.factor(accuracy_table$submission_id)
accuracy_table$accuracy <- as.numeric(accuracy_table$accuracy)
accuracy_table$n <- as.factor(accuracy_table$n)
accu_complete <- subset(accuracy_table, select=c(ID, trial_name, stimulus_type, gross_stimulus_type, n, accuracy))
for(id in IDs){
for(n in N){
for(st in stim_types){
howmanyback = n
trial_name = filter(data,submission_id==id)$trial_name[1]
gr_st = filter(data, stim_type == st)$gross_stimtype[1]
n_correct = sum( filter(cg2, (submission_id == id && stim_type == st) && (n == howmanyback && correctness == "correct"))$nn )
n_total = sum( filter(cg2, (submission_id == id && n == howmanyback) && stim_type == st)$nn )
accuracy = n_correct/n_total
entry = data.frame(submission_id = id, trial_name = trial_name, stimulus_type = st, gross_stimulus_type = gr_st, n = howmanyback, accuracy = accuracy, count = n_total)
accu_complete <- rbind(accu_complete, entry)
}
}
}
head(accu_complete)
accu_complete$submission_id <- as.factor(accu_complete$submission_id)
accu_complete$n <- as.factor(accu_complete$n)
ggplot(accu_complete,mapping=aes(x=gross_stimulus_type, y=accuracy, color=n))+
geom_boxplot()
accu_complete <- rosner_outlier_removal(accu_complete, var.col=accu_complete$accuracy, crit.value=3)
ggplot(data=accu_complete.woo, mapping=aes(x=stimulus_type, y=accuracy, color=n))+
geom_boxplot()
names(accu_complete)
formula = bf(accuracy ~ stimulus_type*n+(1|submission_id)+(1|trial_name),
sigma ~ stimulus_type*n+(1|submission_id) + (1|trial_name))
accu_complete.mdl.brm = brm(formula, data=accu_complete, family="student")
accu_complete.mdl.brm
